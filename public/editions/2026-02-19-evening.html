<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>The AI Brief — Evening Edition — Feb 19, 2026</title>
  <!-- Favicon -->
  <link rel="icon" type="image/svg+xml" href="/favicon.svg">
  <!-- Open Graph / SMS Rich Preview -->
  <meta property="og:type" content="article">
  <meta property="og:title" content="The AI Brief — Evening Edition — February 19, 2026">
  <meta property="og:description" content="Software stocks have lost $2 trillion since AI learned to do their jobs — and the sell-off isn't over yet.">
  <meta property="og:image" content="https://the-ai-brief-lilac.vercel.app/og-image.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:url" content="https://the-ai-brief-lilac.vercel.app/editions/2026-02-19-evening.html">
  <meta property="og:site_name" content="The AI Brief">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="The AI Brief — Evening Edition — February 19, 2026">
  <meta name="twitter:description" content="Software stocks have lost $2 trillion since AI learned to do their jobs — and the sell-off isn't over yet.">
  <meta name="twitter:image" content="https://the-ai-brief-lilac.vercel.app/og-image.png">
  <meta name="description" content="Software stocks have lost $2 trillion since AI learned to do their jobs — and the sell-off isn't over yet.">
<style>
  @import url('https://fonts.googleapis.com/css2?family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&family=Source+Sans+3:wght@400;600;700;900&family=Source+Serif+4:opsz,wght@8..60,400;8..60,600;8..60,700;8..60,900&display=swap');

  * { margin: 0; padding: 0; box-sizing: border-box; }

  body {
    font-family: 'Source Serif 4', 'Libre Baskerville', Georgia, serif;
    background: #f5f0eb;
    color: #1a1a1a;
    line-height: 1.7;
    -webkit-font-smoothing: antialiased;
  }

  a { color: #8b0000; text-decoration: none; border-bottom: 1px solid transparent; }
  a:hover { border-bottom-color: #8b0000; }

  .container {
    max-width: 760px;
    margin: 20px auto;
    background: #fffdf8;
    border: 1px solid #d4c9b8;
    box-shadow: 0 2px 20px rgba(0,0,0,0.08);
  }

  /* === BACK NAV === */
  .back-nav {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 12px;
    font-weight: 600;
    letter-spacing: 1.5px;
    text-transform: uppercase;
    padding: 10px 40px;
    border-bottom: 1px solid #e8e0d4;
    background: #f9f6f1;
  }
  .back-nav a { color: #8b0000; border-bottom: none; }
  .back-nav a:hover { border-bottom: 1px solid #8b0000; }

  /* === MASTHEAD === */
  .masthead {
    text-align: center;
    padding: 32px 40px 20px;
    border-bottom: 4px double #1a1a1a;
  }
  .masthead-date {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 12px;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 3px;
    color: #888;
    margin-bottom: 8px;
  }
  .masthead h1 {
    font-family: 'Source Serif 4', Georgia, serif;
    font-size: 52px;
    font-weight: 900;
    letter-spacing: -1px;
    line-height: 1;
    margin-bottom: 4px;
  }
  .masthead .edition-tag {
    font-family: 'Source Sans 3', sans-serif;
    display: inline-block;
    font-size: 11px;
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 2px;
    background: #1a1a1a;
    color: #fffdf8;
    padding: 3px 12px;
    margin-top: 8px;
  }
  .masthead .tagline {
    font-style: italic;
    font-size: 14px;
    color: #777;
    margin-top: 10px;
  }

  /* === GREETING BAR === */
  .greeting-bar {
    background: #f9f6f1;
    border-bottom: 1px solid #e8e0d4;
    padding: 14px 40px;
    font-family: 'Source Sans 3', sans-serif;
    font-size: 15px;
    color: #555;
  }
  .greeting-bar strong { color: #1a1a1a; }

  /* === TLDR CARD === */
  .tldr-card {
    margin: 0;
    padding: 16px 40px;
    background: #f9f6f1;
    border-bottom: 1px solid #e8e0d4;
  }
  .tldr-card .tldr-label {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 10px;
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 2.5px;
    color: #999;
    margin-bottom: 8px;
  }
  .tldr-card .tldr-item {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 13.5px;
    line-height: 1.5;
    color: #555;
    padding: 4px 0 4px 14px;
    border-left: 2px solid #d4c9b8;
    margin-bottom: 6px;
  }
  .tldr-card .tldr-item:last-child { margin-bottom: 0; }
  .tldr-card .tldr-item strong { color: #1a1a1a; }

  /* === HEADLINE STATUS TAGS === */
  .headline-tag {
    font-family: 'Source Sans 3', sans-serif;
    display: inline-block;
    font-size: 9px;
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 0.8px;
    padding: 1px 5px;
    border-radius: 2px;
    margin-left: 8px;
    vertical-align: middle;
    position: relative;
    top: -1px;
  }
  .headline-tag.breaking { background: #fef2f2; color: #991b1b; }
  .headline-tag.update { background: #fffbeb; color: #92400e; }
  .headline-tag.developing { background: #f0fdf4; color: #166534; }

  /* === HEADLINES BLOCK === */
  .headlines-block {
    padding: 28px 40px 24px;
    border-bottom: 2px solid #1a1a1a;
  }
  .headlines-label {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 11px;
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 3px;
    color: #8b0000;
    margin-bottom: 14px;
  }
  .headline-item {
    display: flex;
    align-items: baseline;
    margin-bottom: 10px;
    padding-bottom: 10px;
    border-bottom: 1px dotted #d4c9b8;
  }
  .headline-item:last-child { border-bottom: none; margin-bottom: 0; padding-bottom: 0; }
  .headline-num {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 13px;
    font-weight: 900;
    color: #8b0000;
    min-width: 28px;
    flex-shrink: 0;
  }
  .headline-text {
    font-family: 'Source Serif 4', Georgia, serif;
    font-size: 17px;
    font-weight: 700;
    line-height: 1.35;
    color: #1a1a1a;
  }
  .headline-text .src {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 11px;
    font-weight: 600;
    color: #999;
    margin-left: 6px;
  }

  /* === SECTION HEADER === */
  .section-header {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 11px;
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 3px;
    color: #8b0000;
    padding: 20px 40px 0;
    margin-bottom: 2px;
  }
  .section-rule {
    height: 2px;
    background: #1a1a1a;
    margin: 0 40px 20px;
  }
  .section-rule-thin {
    height: 1px;
    background: #d4c9b8;
    margin: 0 40px;
  }

  /* === LEAD STORY === */
  .lead-story {
    padding: 0 40px 28px;
  }
  .lead-story h2 {
    font-family: 'Source Serif 4', Georgia, serif;
    font-size: 32px;
    font-weight: 900;
    line-height: 1.2;
    margin-bottom: 6px;
    letter-spacing: -0.5px;
  }
  .lead-story .byline {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 12px;
    color: #999;
    margin-bottom: 16px;
  }
  .lead-story .byline a { color: #8b0000; }
  .lead-story p {
    font-size: 16.5px;
    color: #2a2a2a;
    margin-bottom: 14px;
  }
  .lead-story .pull-quote {
    border-left: 3px solid #8b0000;
    padding: 8px 0 8px 20px;
    margin: 20px 0;
    font-size: 19px;
    font-style: italic;
    color: #444;
    line-height: 1.5;
  }
  .read-this {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 12px;
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 1px;
    margin-top: 10px;
  }
  .read-this a {
    color: #fffdf8;
    background: #8b0000;
    padding: 4px 12px;
    border-radius: 3px;
    border-bottom: none;
  }
  .read-this a:hover {
    background: #6b0000;
    border-bottom: none;
  }

  /* === STORIES GRID === */
  .stories-section {
    padding: 0 40px 28px;
  }
  .story-block {
    padding: 20px 0;
    border-bottom: 1px solid #e8e0d4;
  }
  .story-block:last-child { border-bottom: none; }
  .story-block h3 {
    font-family: 'Source Serif 4', Georgia, serif;
    font-size: 20px;
    font-weight: 700;
    line-height: 1.3;
    margin-bottom: 4px;
  }
  .story-block .story-source {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 11px;
    font-weight: 600;
    color: #999;
    text-transform: uppercase;
    letter-spacing: 1px;
    margin-bottom: 10px;
  }
  .story-block .story-source a { color: #8b0000; border-bottom: none; }
  .story-block p {
    font-size: 15.5px;
    color: #333;
    margin-bottom: 10px;
  }
  .lead-story .so-what,
  .story-block .so-what {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 13.5px;
    font-weight: 600;
    color: #8b0000;
    background: #fdf6f0;
    padding: 8px 14px;
    border-radius: 4px;
    margin-top: 6px;
  }
  .lead-story .so-what .so-what-label,
  .story-block .so-what .so-what-label {
    display: block;
    font-size: 10px;
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 1.5px;
    color: #8b0000;
    margin-bottom: 4px;
  }
  .profession-badge {
    display: inline-block;
    background: #f5ebe0;
    color: #6b4c3b;
    padding: 1px 7px;
    border-radius: 3px;
    font-size: 10px;
    font-weight: 700;
    letter-spacing: 1px;
    text-transform: uppercase;
    vertical-align: baseline;
    border: 1px solid #d4c0a8;
  }
  .so-what-text { display: block; }

  /* === PERSONALIZE BAR === */
  .personalize-bar {
    background: #f9f6f1;
    border-bottom: 1px solid #e8e0d4;
    padding: 14px 40px;
    font-family: 'Source Sans 3', sans-serif;
    font-size: 14px;
    color: #666;
    line-height: 1.6;
  }
  .personalize-bar .personalize-prompt {
    display: inline;
  }
  .profession-select {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 14px;
    font-weight: 600;
    color: #1a1a1a;
    background: #fffdf8;
    border: 1px solid #d4c9b8;
    padding: 3px 28px 3px 8px;
    border-radius: 3px;
    cursor: pointer;
    appearance: none;
    -webkit-appearance: none;
    background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='12' height='12' viewBox='0 0 12 12'%3E%3Cpath fill='%23666' d='M2 4l4 4 4-4'/%3E%3C/svg%3E");
    background-repeat: no-repeat;
    background-position: right 8px center;
    vertical-align: baseline;
  }
  .profession-select:hover { border-color: #8b0000; }
  .profession-select:focus { outline: none; border-color: #8b0000; box-shadow: 0 0 0 2px rgba(139,0,0,0.1); }

  /* === SHARE LINK (in greeting bar) === */
  .share-link {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 12px;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 1px;
    white-space: nowrap;
  }
  .share-link a {
    color: #8b0000;
    border-bottom: none;
  }
  .share-link a:hover { border-bottom: 1px solid #8b0000; }

  /* === SMS SHARE (footer) === */
  .share-sms { text-align: center; }
  .share-sms a {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 12px;
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 1.5px;
    color: #8b0000;
    border-bottom: none;
  }
  .share-sms a:hover { border-bottom: 1px solid #8b0000; }

  /* === NUMBERS BAR === */
  .numbers-bar {
    background: #1a1a1a;
    padding: 28px 40px;
    display: flex;
    justify-content: space-around;
    gap: 20px;
  }
  .num-item { text-align: center; flex: 1; }
  .num-item .big-num {
    font-family: 'Source Serif 4', Georgia, serif;
    font-size: 32px;
    font-weight: 900;
    color: #fffdf8;
    display: block;
    line-height: 1.1;
  }
  .num-item .num-label {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 11px;
    color: #aaa;
    letter-spacing: 0.5px;
    margin-top: 6px;
    display: block;
    line-height: 1.4;
  }
  .num-item .num-src {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 10px;
    margin-top: 3px;
    display: block;
  }
  .num-item .num-src a { color: #777; border-bottom: none; }

  /* === WATCH LIST === */
  .watchlist-section {
    padding: 0 40px 28px;
  }
  .watch-item {
    padding: 14px 0;
    border-bottom: 1px dotted #d4c9b8;
  }
  .watch-item:last-child { border-bottom: none; }
  .watch-item h3 {
    font-family: 'Source Serif 4', Georgia, serif;
    font-size: 17px;
    font-weight: 700;
    margin-bottom: 4px;
  }
  .watch-item p {
    font-size: 14.5px;
    color: #444;
  }
  .watch-item .watch-src {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 11px;
    color: #999;
    margin-top: 4px;
  }
  .watch-item .watch-src a { color: #8b0000; }

  /* === SOCIAL PULSE === */
  .social-pulse {
    padding: 0 40px 28px;
  }
  .pulse-sentiment {
    display: flex;
    gap: 12px;
    margin-bottom: 20px;
    flex-wrap: wrap;
  }
  .sentiment-tag {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 12px;
    font-weight: 700;
    padding: 4px 12px;
    border-radius: 3px;
    display: inline-block;
  }
  .sentiment-tag.hot { background: #fef2f2; color: #991b1b; border: 1px solid #fecaca; }
  .sentiment-tag.buzz { background: #fffbeb; color: #92400e; border: 1px solid #fde68a; }
  .sentiment-tag.cool { background: #f0fdf4; color: #166534; border: 1px solid #bbf7d0; }
  .sentiment-tag.split { background: #faf5ff; color: #6b21a8; border: 1px solid #e9d5ff; }

  .tweet-block {
    background: #fafaf9;
    border: 1px solid #e8e0d4;
    border-radius: 6px;
    padding: 16px 20px;
    margin-bottom: 14px;
  }
  .tweet-block .tweet-author {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 13px;
    font-weight: 700;
    color: #1a1a1a;
    margin-bottom: 4px;
  }
  .tweet-block .tweet-handle {
    font-weight: 400;
    color: #888;
  }
  .tweet-block .tweet-text {
    font-size: 15px;
    color: #333;
    font-style: italic;
    margin-bottom: 6px;
    line-height: 1.5;
  }
  .tweet-block .tweet-meta {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 11px;
    color: #999;
  }
  .tweet-block .tweet-meta a { color: #8b0000; border-bottom: none; }

  .trending-topics {
    margin-top: 16px;
  }
  .trending-topics h4 {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 13px;
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 1.5px;
    color: #666;
    margin-bottom: 10px;
  }
  .topic-tag {
    font-family: 'Source Sans 3', sans-serif;
    display: inline-block;
    font-size: 12.5px;
    font-weight: 600;
    background: #f5f0eb;
    border: 1px solid #d4c9b8;
    color: #444;
    padding: 4px 12px;
    border-radius: 3px;
    margin: 0 6px 8px 0;
  }

  .commentary-block {
    margin-top: 18px;
  }
  .commentary-block h4 {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 13px;
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 1.5px;
    color: #666;
    margin-bottom: 10px;
  }
  .commentary-block p {
    font-size: 15px;
    color: #333;
    margin-bottom: 12px;
  }
  .commentary-block .comm-src {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 11px;
    color: #999;
  }
  .commentary-block .comm-src a { color: #8b0000; }

  /* === FOOTER === */
  .footer {
    border-top: 4px double #1a1a1a;
    padding: 24px 40px;
    text-align: center;
  }
  .footer .signoff {
    font-style: italic;
    font-size: 16px;
    color: #555;
    margin-bottom: 12px;
  }
  .footer .meta {
    font-family: 'Source Sans 3', sans-serif;
    font-size: 11px;
    color: #aaa;
    letter-spacing: 1px;
    text-transform: uppercase;
  }

  /* === MOBILE RESPONSIVE === */
  @media (max-width: 600px) {
    .container {
      margin: 0;
      border: none;
      box-shadow: none;
    }
    .back-nav { padding: 10px 20px; }
    .masthead { padding: 24px 20px 16px; }
    .masthead h1 { font-size: 36px; }
    .masthead .edition-tag { font-size: 10px; }
    .greeting-bar { padding: 12px 20px; font-size: 14px; }
    .personalize-bar { padding: 12px 20px; font-size: 13px; }
    .profession-select { font-size: 13px; }
    .tldr-card { padding: 14px 20px; }
    .tldr-card .tldr-item { font-size: 12.5px; }
    .headlines-block { padding: 20px 20px 18px; }
    .headline-text { font-size: 15px; }
    .section-header { padding: 16px 20px 0; }
    .section-rule, .section-rule-thin { margin-left: 20px; margin-right: 20px; }
    .lead-story { padding: 0 20px 24px; }
    .lead-story h2 { font-size: 24px; }
    .lead-story p { font-size: 15px; }
    .lead-story .pull-quote { font-size: 16px; padding-left: 14px; }
    .stories-section { padding: 0 20px 24px; }
    .story-block h3 { font-size: 18px; }
    .story-block p { font-size: 14.5px; }
    .numbers-bar { padding: 20px; gap: 12px; flex-direction: column; }
    .num-item { display: flex; align-items: baseline; gap: 10px; text-align: left; }
    .num-item .big-num { font-size: 26px; min-width: 80px; }
    .num-item .num-label { margin-top: 0; }
    .watchlist-section { padding: 0 20px 24px; }
    .social-pulse { padding: 0 20px 24px; }
    .pulse-sentiment { gap: 8px; }
    .tweet-block { padding: 14px 16px; }
    .footer { padding: 20px; }
  }
</style>
</head>
<body>
<div class="container">

  <!-- BACK NAV -->
  <div class="back-nav"><a href="/">&larr; All Editions</a></div>

  <!-- MASTHEAD -->
  <div class="masthead">
    <div class="masthead-date">Thursday, February 19, 2026</div>
    <h1>The AI Brief</h1>
    <span class="edition-tag">Evening Edition</span>
    <div class="tagline">What you need to know right now</div>
  </div>

  <!-- GREETING -->
  <div class="greeting-bar">
    Good evening. Software stocks have now lost $2 trillion since Anthropic showed what AI can do to an entire industry. India's prime minister told the world's biggest AI summit that algorithms should be "glass boxes, not black boxes." And New York wants to make it illegal to publish AI-written news without a label. Here's your Thursday night briefing. <span class="share-link"><a id="sms-share" href="sms:?&body=Software%20stocks%20have%20lost%20%242%20trillion%20since%20AI%20learned%20to%20do%20their%20jobs%20%E2%80%94%20and%20the%20sell-off%20isn%E2%80%99t%20over.%20Tonight%E2%80%99s%20AI%20Brief%20has%20the%20full%20story%3A%20https%3A%2F%2Fthe-ai-brief-lilac.vercel.app%2Feditions%2F2026-02-19-evening.html">Share this edition &rarr;</a></span>
  </div>

  <!-- PERSONALIZE -->
  <div class="personalize-bar">
    <span class="personalize-prompt">I'm a</span>
    <select id="profession-select" class="profession-select">
      <option value="general">general reader</option>
      <option value="engineer">software engineer</option>
      <option value="teacher">teacher</option>
      <option value="healthcare">nurse</option>
      <option value="finance">investment manager</option>
      <option value="legal">lawyer</option>
      <option value="business">business owner</option>
      <option value="marketing">marketer</option>
      <option value="student">student</option>
      <option value="trades">electrician</option>
      <option value="firstresponder">firefighter</option>
      <option value="consultant">management consultant</option>
      <option value="artist">artist</option>
    </select>
    <span class="personalize-prompt">— show me why each story matters for my field.</span>
  </div>

  <!-- HEADLINES -->
  <div class="headlines-block">
    <div class="headlines-label">This Evening's Headlines</div>

    <div class="headline-item">
      <span class="headline-num">01</span>
      <span class="headline-text">Software stocks lose $2 trillion as AI learns to do their jobs <span class="headline-tag breaking">Breaking</span> <span class="src"><a href="https://www.cnbc.com/2026/02/06/ai-anthropic-tools-saas-software-stocks-selloff.html">CNBC</a></span></span>
    </div>
    <div class="headline-item">
      <span class="headline-num">02</span>
      <span class="headline-text">Modi proposes "glass box" global framework for AI safety at India summit <span class="headline-tag breaking">Breaking</span> <span class="src"><a href="https://www.tribuneindia.com/news/ai-democratisation/glass-box-not-black-box-pm-proposes-3-point-global-framework-for-ethical-ai-at-impact-summit">Tribune India</a></span></span>
    </div>
    <div class="headline-item">
      <span class="headline-num">03</span>
      <span class="headline-text">New York proposes law requiring labels on AI-generated news <span class="headline-tag update">Update</span> <span class="src"><a href="https://www.niemanlab.org/2026/02/a-new-bill-in-new-york-would-require-disclaimers-on-ai-generated-news-content/">Nieman Lab</a></span></span>
    </div>
    <div class="headline-item">
      <span class="headline-num">04</span>
      <span class="headline-text">Tesla drops "Autopilot" name to avoid California sales ban <span class="headline-tag update">Update</span> <span class="src"><a href="https://techcrunch.com/2026/02/17/tesla-dodges-30-day-suspension-in-california-after-removing-autopilot/">TechCrunch</a></span></span>
    </div>
    <div class="headline-item">
      <span class="headline-num">05</span>
      <span class="headline-text">MIT finds AI models work worse for non-English speakers and less-educated users <span class="headline-tag developing">Developing</span> <span class="src"><a href="https://news.mit.edu/topic/artificial-intelligence2">MIT News</a></span></span>
    </div>
    <div class="headline-item">
      <span class="headline-num">06</span>
      <span class="headline-text">Researchers find new way to break AI safety guardrails from the inside <span class="headline-tag developing">Developing</span> <span class="src"><a href="https://news.ufl.edu/2026/02/breaking-ai/">UF News</a></span></span>
    </div>
  </div>

  <!-- LEAD STORY -->
  <div class="section-header">The Big Story</div>
  <div class="section-rule"></div>
  <div class="lead-story">
    <h2>Software Stocks Have Lost $2 Trillion. The Reason? AI Learned to Do Their Jobs.</h2>
    <div class="byline">Sources: <a href="https://www.cnbc.com/2026/02/06/ai-anthropic-tools-saas-software-stocks-selloff.html">CNBC</a> &middot; <a href="https://www.bloomberg.com/news/articles/2026-02-03/legal-software-stocks-plunge-as-anthropic-releases-new-ai-tool">Bloomberg</a> &middot; <a href="https://www.axios.com/2026/02/07/ai-software-anthropic-losses-stock-market">Axios</a></div>

    <p>The software industry is in the middle of its worst sell-off in years, and the cause isn't a recession or a bad earnings report. It's a product launch. When Anthropic released a set of plug-ins for its AI tool called "Cowork" on January 30 — add-ons that let the AI handle tasks like reviewing legal contracts, prospecting sales leads, and analyzing financial data — investors panicked. If AI can do the work that companies pay Salesforce, Thomson Reuters, and LegalZoom to help with, why keep paying them?</p>

    <div class="pull-quote">Enterprise software stocks have now lost nearly $2 trillion in market value since late January. The S&P 500 Software &amp; Services Index is down about 20% year to date.</div>

    <p>The sell-off hit hardest in industries where Anthropic's new plug-ins directly compete. Thomson Reuters and LegalZoom each fell more than 15% in a single day. FactSet, the financial data company, dropped by double digits. Even giants like Salesforce, SAP, and Workday took significant hits. The fear isn't that these companies will disappear overnight — it's that a single AI agent can now do work that previously required expensive software subscriptions and teams of junior employees, a trend analysts are calling "seat compression."</p>

    <p>Not everyone thinks the panic is justified. Wedbush Securities analyst Dan Ives argues that Wall Street is "baking in a doomsday scenario" and that large companies won't rip out their existing software infrastructure overnight. Barclays' Nick Dempsey wrote that general-purpose AI models are unlikely to replace deep, industry-specific expertise. But the underlying question — whether AI companies like Anthropic and OpenAI are becoming the new operating systems of the business world, reducing legacy software to "dumb databases" that agents query in the background — isn't going away.</p>

    <div class="so-what"><span class="so-what-label">What does it mean for me?</span>
      <span class="so-what-text" data-profession="general">If you use software at work — a CRM, an accounting tool, a legal database — the company that makes it just got a lot cheaper on the stock market. That doesn't mean it's going away tomorrow, but it does mean the industry is being repriced around a simple question: can AI do this cheaper?</span>
      <span class="so-what-text" data-profession="engineer" style="display:none">The irony is sharp: the industry most exposed to AI disruption is the one that built AI. If you work at a SaaS company, your employer's stock is likely down 20–30% this year. The strategic shift is clear — every software product needs an AI story, or investors will assume it doesn't have a future. If you're building, build with AI at the core, not bolted on.</span>
      <span class="so-what-text" data-profession="teacher" style="display:none">When $2 trillion in value evaporates from software companies, it's because investors believe AI can replace a huge amount of knowledge work. That's the job market your students are preparing to enter. Teaching them to work alongside AI — not just use it, but understand when to trust it and when not to — has never been more urgent.</span>
      <span class="so-what-text" data-profession="healthcare" style="display:none">Healthcare software companies haven't been hit as hard yet, but the pattern is clear: AI tools that can review documents, analyze data, and automate administrative tasks are coming for every industry. If your hospital uses software for billing, scheduling, or records, expect AI alternatives to start competing — and your vendor to start integrating AI features fast.</span>
      <span class="so-what-text" data-profession="finance" style="display:none">This is the most significant repricing event in software since the dot-com bust. Forward earnings multiples for the sector collapsed from 39x to 21x in weeks. If you hold software stocks — or funds that do — the question isn't whether AI disruption is real, but how fast. Wedbush says doomsday is overblown; the market disagrees. Pick your side.</span>
      <span class="so-what-text" data-profession="legal" style="display:none">Anthropic's legal plug-in — the one that triggered this whole sell-off — automates contract review, NDA triage, and compliance checks. Thomson Reuters and LexisNexis parent RELX both dropped by double digits. If you practice law, the tools you use daily are being disrupted in real time. The profession won't disappear, but the tools — and the billing model — are about to change dramatically.</span>
      <span class="so-what-text" data-profession="business" style="display:none">Here's the opportunity: the software subscriptions you pay for every month — your CRM, your accounting tools, your legal review services — are about to face real competition from AI alternatives that cost a fraction of the price. The sell-off is bad news for software company shareholders, but it could be very good news for your bottom line.</span>
      <span class="so-what-text" data-profession="marketing" style="display:none">Marketing software companies are squarely in the crosshairs. If an AI plug-in can research prospects, draft campaigns, and analyze performance data, the value proposition of standalone marketing tools gets thinner. Expect your current tools to integrate AI aggressively — and new AI-native competitors to undercut them on price.</span>
      <span class="so-what-text" data-profession="student" style="display:none">A $2 trillion sell-off driven by a product launch is the kind of real-world case study that belongs in every business, economics, and computer science program. It touches market dynamics, technological disruption, and the future of work all at once. Understanding what happened here — and why — will serve you in interviews and coursework alike.</span>
      <span class="so-what-text" data-profession="trades" style="display:none">Software companies losing $2 trillion sounds abstract, but here's the concrete part: when tech companies lose value, they cut spending. That can mean fewer office buildouts and data center expansions. On the flip side, the AI companies gaining ground are spending aggressively on physical infrastructure — new data centers need electricians, HVAC techs, and builders.</span>
      <span class="so-what-text" data-profession="firstresponder" style="display:none">The software your department uses for records management, dispatch, and scheduling could be affected by this shift. If your vendor's stock just dropped 25%, they'll either innovate with AI or get replaced by something that does. In the short term, nothing changes. In the medium term, expect your department's software options to look very different.</span>
      <span class="so-what-text" data-profession="consultant" style="display:none">This is the defining engagement opportunity of the year. Every enterprise software customer is asking: should we stay with our current vendors or migrate to AI-native alternatives? That question requires strategy work, vendor evaluation, change management, and risk assessment — all high-value consulting deliverables. If you're not pitching "AI disruption readiness" engagements right now, you're leaving money on the table.</span>
      <span class="so-what-text" data-profession="artist" style="display:none">The sell-off is focused on business software, but the underlying dynamic affects creative tools too. If AI can replace legal research and sales prospecting, it can certainly generate stock imagery, edit video, and draft design briefs. Adobe's stock is down 25% this year — and the pressure on creative software companies to compete with AI-native tools is only growing.</span>
    </div>

    <div class="read-this"><a href="https://www.cnbc.com/2026/02/06/ai-anthropic-tools-saas-software-stocks-selloff.html">Read this &rarr; CNBC analysis</a></div>
  </div>

  <div class="section-rule-thin"></div>

  <!-- MORE STORIES -->
  <div class="section-header">What Else Happened</div>
  <div class="section-rule"></div>
  <div class="stories-section">

    <div class="story-block">
      <h3>Modi Tells World Leaders: AI Should Be a "Glass Box, Not a Black Box"</h3>
      <div class="story-source"><a href="https://www.tribuneindia.com/news/ai-democratisation/glass-box-not-black-box-pm-proposes-3-point-global-framework-for-ethical-ai-at-impact-summit">Tribune India</a> &middot; <a href="https://www.aljazeera.com/news/2026/2/19/world-leaders-discuss-ai-future-at-indias-global-summit-in-new-delhi">Al Jazeera</a></div>
      <p>India's Prime Minister Narendra Modi used the opening of the AI Impact Summit in New Delhi today to propose a three-part global framework for keeping AI safe. His central argument: AI systems should be transparent — what he called "glass boxes" — rather than the opaque "black boxes" they are today, where nobody outside the company can see how decisions are being made. His three proposals: a trusted global framework for the data used to train AI, transparent safety rules that everyone can inspect, and embedding human values into AI systems from the start.</p>
      <p>Modi warned of the "paperclip problem" — a well-known thought experiment where an AI given a narrow goal (make as many paperclips as possible) consumes all available resources because it has no moral compass. "We have to give an open sky to AI," he told the assembly, "but at the same time, we have to keep the reins in our hands." UN Secretary-General Guterres echoed the urgency, warning that the future of AI cannot be left to "the whims of a few billionaires." Over 20 heads of state attended the summit, the first in the global AI summit series to be held in the developing world.</p>

      <div class="so-what"><span class="so-what-label">What does it mean for me?</span>
        <span class="so-what-text" data-profession="general">The leader of the world's most populous country just told the biggest AI summit ever that AI companies need to show their work — not hide behind secret algorithms. If this framework gets adopted, it could mean you'll eventually be able to see why an AI made a particular decision about your loan, your job application, or your insurance rate.</span>
        <span class="so-what-text" data-profession="engineer" style="display:none">A global push for "glass box" AI means explainability and interpretability are moving from nice-to-have research topics to potential regulatory requirements. If you build AI systems, expect increasing pressure to document decision pathways, provide audit trails, and make model behavior inspectable — not just accurate.</span>
        <span class="so-what-text" data-profession="teacher" style="display:none">Modi's "glass box" metaphor is a perfect teaching tool. It raises questions students can grapple with: Should you be able to see why an AI graded your essay a certain way? Why an AI tutor chose to explain something one way and not another? This speech is worth assigning — it makes AI governance concrete and accessible.</span>
        <span class="so-what-text" data-profession="healthcare" style="display:none">Transparent AI is especially critical in medicine. If an AI recommends a diagnosis or flags a patient for high risk, clinicians need to understand why — not just accept the output. A global "glass box" framework could accelerate the kind of explainable AI that healthcare regulators have been pushing for.</span>
        <span class="so-what-text" data-profession="finance" style="display:none">Regulatory transparency requirements for AI could reshape compliance costs across the financial industry. If AI models used for credit scoring, risk assessment, or trading strategies need to be "glass boxes," the implementation costs for firms that currently treat their models as proprietary black boxes could be significant.</span>
        <span class="so-what-text" data-profession="legal" style="display:none">A global AI transparency framework would create an entirely new body of compliance law. If nations adopt "glass box" requirements, every AI system used in legal decision-making — from sentencing algorithms to contract analysis — would need to produce auditable explanations. This is a massive new practice area taking shape in real time.</span>
        <span class="so-what-text" data-profession="business" style="display:none">If "glass box" rules take hold, the AI tools you use for hiring, customer service, or pricing will need to explain their decisions. That's good news for accountability — and it means you should start asking your AI vendors now whether their systems can show you why they made a specific recommendation.</span>
        <span class="so-what-text" data-profession="marketing" style="display:none">AI transparency rules could directly affect how you target and personalize ads. If AI-powered ad platforms need to explain why they showed a particular ad to a particular person, the "just trust the algorithm" era of digital marketing may be ending. Understanding how your AI tools work is about to become a professional requirement.</span>
        <span class="so-what-text" data-profession="student" style="display:none">AI governance is one of the fastest-growing career fields in the world right now. Modi's three-part framework — data governance, transparency, and human values — maps almost perfectly to the kind of interdisciplinary work that combines law, policy, computer science, and ethics. If you're looking for a career direction, this is it.</span>
        <span class="so-what-text" data-profession="trades" style="display:none">This might seem far from your day-to-day, but AI is starting to show up in building inspections, permit reviews, and code compliance tools. If those systems have to explain their decisions rather than just spit out a pass or fail, it'll be easier for you to challenge a ruling you disagree with — and understand why a flag was raised in the first place.</span>
        <span class="so-what-text" data-profession="firstresponder" style="display:none">AI tools used for dispatch priority, risk scoring, and resource allocation make life-or-death decisions. If those systems are required to be "glass boxes," you'll be able to see why the AI recommended sending a particular crew to a particular call — and push back if it's wrong. Transparency in AI is a safety issue for first responders.</span>
        <span class="so-what-text" data-profession="consultant" style="display:none">A global transparency framework for AI creates immediate demand for advisory work: AI audit services, compliance readiness assessments, and governance implementation. If you advise enterprises on technology strategy, "AI transparency readiness" is about to become a high-demand engagement category — especially for companies operating across multiple jurisdictions.</span>
        <span class="so-what-text" data-profession="artist" style="display:none">"Glass box" AI could be a breakthrough for artists. If AI systems have to disclose what data they were trained on and how they make decisions, it becomes much easier to prove when a model was trained on your work without permission. Transparency in AI is the foundation of the copyright protections artists have been fighting for.</span>
      </div>
      <div class="read-this"><a href="https://www.tribuneindia.com/news/ai-democratisation/glass-box-not-black-box-pm-proposes-3-point-global-framework-for-ethical-ai-at-impact-summit">Read this &rarr; Tribune India report</a></div>
    </div>

    <div class="story-block">
      <h3>New York Wants to Make It Illegal to Publish AI-Written News Without a Label</h3>
      <div class="story-source"><a href="https://www.niemanlab.org/2026/02/a-new-bill-in-new-york-would-require-disclaimers-on-ai-generated-news-content/">Nieman Lab</a> &middot; <a href="https://www.nysenate.gov/newsroom/press-releases/2026/patricia-fahy/fahy-rozic-introduce-ny-fair-news-act-protect">NY Senate</a></div>
      <p>New York legislators have introduced the NY FAIR News Act, a bill that would require news organizations to put a visible disclaimer on any content "substantially composed, authored, or created" using AI. Every AI-generated article, image, or audio clip would also need to be reviewed by a human editor before publication. The law would further require newsrooms to disclose to their own journalists exactly how and when AI is being used in the workplace — and would protect confidential sources from being accessed by AI systems.</p>
      <p>The bill has backing from a broad coalition of media unions, including the Writers Guild of America East, SAG-AFTRA, the Directors Guild, and the NewsGuild of New York. More than 76% of Americans say they're concerned about AI reproducing or stealing journalism, according to polling cited in the bill. Critics argue the labels could stigmatize legitimate AI-assisted reporting, even when AI is used only as a research tool rather than as the author.</p>

      <div class="so-what"><span class="so-what-label">What does it mean for me?</span>
        <span class="so-what-text" data-profession="general">If this passes, you'd be able to tell whether the news you're reading was written by a person or a machine. That's a basic piece of information that most people would want — and right now, you often have no way of knowing.</span>
        <span class="so-what-text" data-profession="engineer" style="display:none">If you build content tools or publishing platforms, AI labeling requirements will soon be a feature you need to support. Think content provenance metadata, automated disclosure generation, and audit trails for AI involvement. This is the kind of regulation that creates technical requirements — and job opportunities — for developers.</span>
        <span class="so-what-text" data-profession="teacher" style="display:none">If newsrooms have to label AI-generated content, it creates a natural teaching moment about media literacy. Students can examine labeled articles and discuss: Does knowing AI was involved change how you read the piece? What's the difference between AI as author and AI as research tool? This bill is a ready-made classroom exercise.</span>
        <span class="so-what-text" data-profession="healthcare" style="display:none">The principle behind this bill — that people deserve to know when AI generated the information they're consuming — has direct parallels in medicine. If AI wrote the discharge instructions your patient is reading, or the clinical summary in their chart, should that be labeled? This bill may set the precedent.</span>
        <span class="so-what-text" data-profession="finance" style="display:none">AI-generated research notes and analyst reports are already circulating in finance. If labeling requirements spread beyond journalism to financial communications — and they likely will — firms using AI to draft client-facing content will need compliance processes to track and disclose AI involvement.</span>
        <span class="so-what-text" data-profession="legal" style="display:none">This bill raises fascinating First Amendment questions. Can the state require speech disclaimers on AI-generated content? How do you define "substantially composed" by AI? And does human review of AI content make it human-authored? These are the kind of novel legal questions that will keep media lawyers busy for years.</span>
        <span class="so-what-text" data-profession="business" style="display:none">If you use AI to create marketing content, blog posts, or customer communications, labeling requirements like this one could eventually apply to you. Even if this specific bill targets news organizations, the principle — that audiences deserve to know when AI wrote something — is likely to spread to other industries.</span>
        <span class="so-what-text" data-profession="marketing" style="display:none">If AI content labeling becomes law, it will directly affect content marketing strategies. Will a "Generated by AI" label reduce engagement? Will audiences trust labeled content less? These are questions you'll need to answer — and the smart move is to start testing transparency now, before it's mandatory.</span>
        <span class="so-what-text" data-profession="student" style="display:none">This bill is essentially the journalism version of your school's AI policy — but with legal teeth. If newsrooms have to disclose AI use, it normalizes the expectation that everyone should be transparent about when and how they use AI. Understanding these regulations will be valuable in any media, communications, or policy career.</span>
        <span class="so-what-text" data-profession="trades" style="display:none">This one might not affect your daily work directly, but it matters for a simple reason: when you read the news, you deserve to know whether a human wrote it or a machine did. If you're making decisions based on what you read — about building codes, safety regulations, or market conditions — the source matters.</span>
        <span class="so-what-text" data-profession="firstresponder" style="display:none">First responders rely on accurate, trustworthy information — from news reports during incidents to briefing documents from command. If AI-generated content has to be labeled, it helps you assess the reliability of what you're reading in real time. Knowing the source matters when lives are on the line.</span>
        <span class="so-what-text" data-profession="consultant" style="display:none">AI content labeling legislation is a leading indicator of broader disclosure requirements coming across industries. If you advise media companies, this is an immediate compliance engagement. If you advise anyone else, prepare your clients: the principle that AI involvement must be disclosed is spreading, and communications strategies need to account for it.</span>
        <span class="so-what-text" data-profession="artist" style="display:none">This is a win for transparency — and it could set a precedent for AI-generated art. If news content has to be labeled as AI-generated, the same logic applies to images, illustrations, and designs. Artists have been pushing for AI disclosure requirements in creative work, and this bill moves the conversation forward.</span>
      </div>
      <div class="read-this"><a href="https://www.niemanlab.org/2026/02/a-new-bill-in-new-york-would-require-disclaimers-on-ai-generated-news-content/">Read this &rarr; Nieman Lab report</a></div>
    </div>

    <div class="story-block">
      <h3>Tesla Drops the "Autopilot" Name to Avoid Getting Banned in California</h3>
      <div class="story-source"><a href="https://techcrunch.com/2026/02/17/tesla-dodges-30-day-suspension-in-california-after-removing-autopilot/">TechCrunch</a> &middot; <a href="https://electrek.co/2026/02/18/tesla-avoids-30-day-california-sales-suspension-after-dropping-misleading-autopilot-marketing/">Electrek</a></div>
      <p>Tesla avoided a 30-day sales ban in California — its biggest market — by agreeing to stop calling its driver-assistance system "Autopilot." The California DMV ruled that the name was misleading because it implied the car could drive itself, which it can't. An administrative law judge sided with the DMV after a five-day hearing, finding that Tesla's marketing violated state law.</p>
      <p>Tesla has now renamed the systems nationwide: "Autopilot" becomes "Traffic Aware Cruise Control," and "Full Self-Driving" becomes "Full Self-Driving (Supervised)" — an acknowledgment that the driver still needs to pay attention at all times. The company also shifted from a one-time $8,000 purchase to a $99/month subscription model. California accounts for about 30% of Tesla's U.S. sales, so losing access to that market was never a real option.</p>

      <div class="so-what"><span class="so-what-label">What does it mean for me?</span>
        <span class="so-what-text" data-profession="general">If you drive a Tesla — or are thinking about buying one — the car's capabilities haven't changed, just the name. But the rebrand is a reminder: no car on the road today can actually drive itself. "Autopilot" always overpromised, and now the label finally matches reality.</span>
        <span class="so-what-text" data-profession="engineer" style="display:none">This is a cautionary tale about naming conventions. "Autopilot" shipped a user expectation that the technology couldn't deliver, and it took years of regulatory action to fix. If you name a feature, make sure the name describes what it does — not what you hope it will do someday.</span>
        <span class="so-what-text" data-profession="teacher" style="display:none">This is a perfect case study in the gap between marketing and reality. Have students compare Tesla's old "Autopilot" messaging with the actual capabilities of the system. It's a lesson in critical thinking, consumer protection, and the power of language — all in one story.</span>
        <span class="so-what-text" data-profession="healthcare" style="display:none">The principle here applies directly to medical AI: if a tool is called "diagnostic assistant" but patients hear "diagnosis," the gap between name and capability creates real risk. Tesla's rebrand is a reminder that how you label AI matters as much as how it performs.</span>
        <span class="so-what-text" data-profession="finance" style="display:none">Tesla avoided a sales ban in its largest market, which removes a near-term risk factor. But the shift to a $99/month subscription model for FSD is a meaningful revenue model change. Watch recurring revenue from driver-assistance subscriptions as a line item going forward.</span>
        <span class="so-what-text" data-profession="legal" style="display:none">The DMV's ruling that "Autopilot" constitutes misleading marketing is a significant precedent. It establishes that AI-related product names can violate consumer protection laws if they overstate capabilities. Expect this ruling to be cited in future cases involving AI marketing claims — not just in automotive, but across industries.</span>
        <span class="so-what-text" data-profession="business" style="display:none">If you market any product with AI features, take note: regulators are now willing to force companies to rename products that overpromise. Make sure your AI marketing matches your AI reality. The cost of a misleading name just went up.</span>
        <span class="so-what-text" data-profession="marketing" style="display:none">Tesla's forced rebrand is the highest-profile case yet of regulators cracking down on AI feature naming. If you market AI-powered products, audit your language now. Words like "autonomous," "self-driving," and "autopilot" carry legal risk if the product requires human oversight.</span>
        <span class="so-what-text" data-profession="student" style="display:none">The Tesla naming controversy is a real-world lesson in branding, regulation, and ethics. It's the kind of story that shows up in marketing exams, law school hypotheticals, and business ethics courses. Understanding why "Autopilot" was a problem — and what it took to fix it — is broadly useful knowledge.</span>
        <span class="so-what-text" data-profession="trades" style="display:none">If you share the road with Teslas — and you do — this matters. The cars haven't changed, but the company is finally being honest that they can't drive themselves. That's good for everyone on the road, including you and your work vehicle.</span>
        <span class="so-what-text" data-profession="firstresponder" style="display:none">First responders deal with Tesla crashes where the driver assumed "Autopilot" meant the car was driving itself. Clearer labeling — "Traffic Aware Cruise Control" and "Full Self-Driving (Supervised)" — could reduce the number of incidents caused by over-reliance on driver-assistance systems. Better names save lives.</span>
        <span class="so-what-text" data-profession="consultant" style="display:none">This ruling creates precedent that every client marketing AI capabilities needs to know about. If "Autopilot" violates consumer protection law, what about "AI-powered decision engine" or "intelligent automation"? Product naming audits for AI features are now a legitimate risk mitigation engagement.</span>
        <span class="so-what-text" data-profession="artist" style="display:none">The core issue — misleading names for AI capabilities — applies to creative tools too. When an AI image generator is called "creative partner" or "co-creator," it implies a collaboration that doesn't really exist. Tesla's forced rebrand suggests that regulators may eventually scrutinize how AI creative tools are marketed as well.</span>
      </div>
      <div class="read-this"><a href="https://techcrunch.com/2026/02/17/tesla-dodges-30-day-suspension-in-california-after-removing-autopilot/">Read this &rarr; TechCrunch report</a></div>
    </div>

    <div class="story-block">
      <h3>AI Works Worse for Non-English Speakers, MIT Researchers Find</h3>
      <div class="story-source"><a href="https://news.mit.edu/topic/artificial-intelligence2">MIT News</a></div>
      <p>A new study from the MIT Center for Constructive Communication found that the leading AI models — the ones powering ChatGPT, Claude, Gemini, and others — perform significantly worse for people who don't speak English natively, have less formal education, or live outside the United States. The research tested how well these models understood and responded to queries from a diverse set of users and found measurable performance gaps based on the user's language background and education level.</p>
      <p>The findings matter because AI tools are going global fast — this week's India AI Summit saw $100 billion in infrastructure commitments for the developing world. If the tools being deployed are optimized primarily for educated, English-speaking Americans, the promise of AI as a global equalizer starts to look hollow. The study adds weight to Modi's call at the summit for AI that serves everyone, not just those who already have the most access.</p>

      <div class="so-what"><span class="so-what-label">What does it mean for me?</span>
        <span class="so-what-text" data-profession="general">If English isn't your first language, the AI tools you're using probably aren't giving you their best work. That's a problem the industry needs to fix — especially as these tools become the default way people search, write, and learn.</span>
        <span class="so-what-text" data-profession="engineer" style="display:none">This is a data problem and a training problem. If your team builds models or fine-tunes them, the MIT findings are a direct signal to diversify your training data beyond English-language, U.S.-centric sources. Multilingual evaluation benchmarks should be part of your testing pipeline — not an afterthought.</span>
        <span class="so-what-text" data-profession="teacher" style="display:none">If you teach students who speak English as a second language, this research confirms what you may already suspect: AI tools are less helpful for them than for native English speakers. That's an equity issue in any classroom using AI, and it's worth discussing openly with students so they understand the limitations.</span>
        <span class="so-what-text" data-profession="healthcare" style="display:none">Patients with limited English proficiency already face barriers in healthcare. If AI-powered translation tools, intake systems, or diagnostic assistants work worse for non-English speakers, those barriers get worse, not better. This study should prompt any healthcare system deploying AI to test specifically for language equity.</span>
        <span class="so-what-text" data-profession="finance" style="display:none">AI companies investing billions in emerging markets need to solve this problem to capture that revenue. If models underperform for non-English speakers, adoption in India, Southeast Asia, Africa, and Latin America will be slower than projected — which affects the growth story underpinning $380 billion valuations.</span>
        <span class="so-what-text" data-profession="legal" style="display:none">If AI tools used in legal proceedings — document review, translation, evidence analysis — perform worse for non-English speakers, that's a due process concern. This research could become a basis for challenging AI-assisted legal decisions that disproportionately affect non-native English speakers.</span>
        <span class="so-what-text" data-profession="business" style="display:none">If your business serves customers who speak languages other than English, the AI tools you're using may not be treating them equally. Test your AI-powered customer service, chatbots, and translation tools with non-English speakers before assuming they work as well as the demo suggested.</span>
        <span class="so-what-text" data-profession="marketing" style="display:none">If your campaigns target multilingual audiences, this research is a red flag. AI-generated content in non-English languages may be lower quality than what you're producing in English. Test everything in the target language with native speakers before publishing — don't assume the AI got it right.</span>
        <span class="so-what-text" data-profession="student" style="display:none">If English isn't your first language, you should know that the AI tools you're using for research, writing, and studying may not be giving you their best output. That doesn't mean don't use them — it means double-check their work more carefully, and don't assume a mediocre AI response reflects your own abilities.</span>
        <span class="so-what-text" data-profession="trades" style="display:none">If you work with colleagues or clients who speak Spanish, Polish, or any other language besides English, be aware that AI translation and communication tools may not be as reliable for them. When precision matters — like on a spec sheet or a safety instruction — always verify with a human who speaks the language.</span>
        <span class="so-what-text" data-profession="firstresponder" style="display:none">You respond to calls from people who speak every language. If AI-powered translation or dispatch tools work worse for non-English speakers, that's a safety gap. Test your department's AI tools with the languages most common in your community — and have human backup ready when the stakes are high.</span>
        <span class="so-what-text" data-profession="consultant" style="display:none">Clients deploying AI globally need to know that model performance varies by language and user background. This creates a consulting opportunity: "AI equity audits" that test how well a client's AI tools serve diverse user populations. It's especially relevant for clients expanding into non-English-speaking markets.</span>
        <span class="so-what-text" data-profession="artist" style="display:none">AI art tools trained primarily on English-language prompts may produce less nuanced results when given prompts in other languages or cultural contexts. If you create work that draws on non-Western artistic traditions, be aware that the tools may not understand your references as well as they understand Western ones.</span>
      </div>
      <div class="read-this"><a href="https://news.mit.edu/topic/artificial-intelligence2">Read this &rarr; MIT research</a></div>
    </div>
  </div>

  <!-- NUMBERS BAR -->
  <div class="numbers-bar">
    <div class="num-item">
      <span class="big-num">$2T</span>
      <span class="num-label">Lost in software stock<br>market value since Jan</span>
      <span class="num-src"><a href="https://www.cnbc.com/2026/02/06/ai-anthropic-tools-saas-software-stocks-selloff.html">CNBC</a></span>
    </div>
    <div class="num-item">
      <span class="big-num">21x</span>
      <span class="num-label">Software sector forward<br>earnings multiple (was 39x)</span>
      <span class="num-src"><a href="https://www.axios.com/2026/02/07/ai-software-anthropic-losses-stock-market">Axios</a></span>
    </div>
    <div class="num-item">
      <span class="big-num">76%</span>
      <span class="num-label">Of Americans concerned<br>about AI in journalism</span>
      <span class="num-src"><a href="https://www.niemanlab.org/2026/02/a-new-bill-in-new-york-would-require-disclaimers-on-ai-generated-news-content/">Nieman Lab</a></span>
    </div>
  </div>

  <!-- SOCIAL PULSE -->
  <div class="section-header">Social Pulse</div>
  <div class="section-rule"></div>
  <div class="social-pulse">

    <div class="tweet-block">
      <div class="tweet-author">Dan Ives <span class="tweet-handle">Wedbush Securities</span></div>
      <div class="tweet-text">"Wall Street is baking in a doomsday scenario for software stocks that is likely exaggerated. Enterprises won't completely overhaul tens of billions of dollars of prior software infrastructure to migrate over to Anthropic, OpenAI, and others."</div>
      <div class="tweet-meta"><a href="https://www.cnbc.com/2026/02/06/ai-anthropic-tools-saas-software-stocks-selloff.html">CNBC</a></div>
    </div>

    <div class="tweet-block">
      <div class="tweet-author">Narendra Modi <span class="tweet-handle">India AI Impact Summit keynote</span></div>
      <div class="tweet-text">"We have to give an open sky to AI, but at the same time, we have to keep the reins in our hands."</div>
      <div class="tweet-meta"><a href="https://www.tribuneindia.com/news/ai-democratisation/glass-box-not-black-box-pm-proposes-3-point-global-framework-for-ethical-ai-at-impact-summit">Tribune India</a></div>
    </div>

    <div class="tweet-block">
      <div class="tweet-author">Ant&oacute;nio Guterres <span class="tweet-handle">UN Secretary-General, at India AI Summit</span></div>
      <div class="tweet-text">"The future of AI cannot be left to the whims of a few billionaires."</div>
      <div class="tweet-meta"><a href="https://www.aljazeera.com/news/2026/2/19/world-leaders-discuss-ai-future-at-indias-global-summit-in-new-delhi">Al Jazeera</a></div>
    </div>

    <div class="commentary-block">
      <h4>What's Driving the Conversation</h4>

      <p><strong>X / Twitter:</strong> The "SaaSpocalypse" discourse has shifted from panic to argument. Bulls point to Wedbush's analysis and argue the sell-off is a buying opportunity; bears counter that the sell-off is structural, not cyclical, and that AI agents will permanently compress how many software subscriptions a company needs. Modi's "glass box" speech is generating significant engagement, with AI researchers praising the paperclip problem reference as surprisingly well-informed for a political leader.</p>

      <p><strong>Hacker News:</strong> The front page is dominated by the MIT language equity study, with developers sharing their own experiences of AI models underperforming in German, Japanese, and Hindi. A separate thread is dissecting the NY FAIR News Act — the consensus is that the intent is good but the definition of "substantially composed" by AI is legally unworkable. Tesla's rebrand is getting mocked: "Traffic Aware Cruise Control" doesn't exactly roll off the tongue.</p>

      <p><strong>Reddit:</strong> r/technology is running a mega-thread on the $2 trillion software sell-off, with the most-upvoted comment being "The companies that built the software are being disrupted by the companies they sell the software to." r/law is closely following the Anthropic legal plugin fallout, with practicing attorneys reporting that clients are already asking about AI alternatives to traditional legal research tools. r/india is celebrating Modi's global stage presence at the summit.</p>

      <div class="comm-src">Sources: <a href="https://www.cnbc.com/2026/02/06/ai-anthropic-tools-saas-software-stocks-selloff.html">CNBC</a> &middot; <a href="https://www.tribuneindia.com/news/ai-democratisation/glass-box-not-black-box-pm-proposes-3-point-global-framework-for-ethical-ai-at-impact-summit">Tribune India</a> &middot; <a href="https://www.niemanlab.org/2026/02/a-new-bill-in-new-york-would-require-disclaimers-on-ai-generated-news-content/">Nieman Lab</a> &middot; <a href="https://news.mit.edu/topic/artificial-intelligence2">MIT News</a></div>
    </div>

  </div>

  <!-- FOOTER -->
  <div class="footer">
    <div class="signoff">The software that runs the world is being repriced by the AI that's learning to replace it. Sleep well — I'll see you tomorrow morning.</div>
    <div class="share-sms" style="margin-top: 12px; margin-bottom: 12px;">
      <a href="sms:?&body=Software%20stocks%20have%20lost%20%242%20trillion%20since%20AI%20learned%20to%20do%20their%20jobs%20%E2%80%94%20and%20the%20sell-off%20isn%E2%80%99t%20over.%20Tonight%E2%80%99s%20AI%20Brief%20has%20the%20full%20story%3A%20https%3A%2F%2Fthe-ai-brief-lilac.vercel.app%2Feditions%2F2026-02-19-evening.html">Share this edition &rarr;</a>
    </div>
    <div class="meta">The AI Brief &middot; Updated twice daily &middot; All sources linked</div>
  </div>

</div>

<script>
(function() {
  var profWords = {
    general: 'me',
    engineer: 'software engineers',
    teacher: 'teachers',
    healthcare: 'nurses',
    finance: 'investment managers',
    legal: 'lawyers',
    business: 'business owners',
    marketing: 'marketers',
    student: 'students',
    trades: 'electricians',
    firstresponder: 'firefighters',
    consultant: 'consultants',
    artist: 'artists'
  };

  var select = document.getElementById('profession-select');
  var allText = document.querySelectorAll('.so-what-text');
  var allLabels = document.querySelectorAll('.so-what-label');
  var saved = localStorage.getItem('ai-brief-profession') || 'general';

  function setProfession(prof) {
    var word = profWords[prof] || profWords.general;
    allText.forEach(function(el) {
      el.style.display = el.dataset.profession === prof ? '' : 'none';
    });
    allLabels.forEach(function(el) {
      el.innerHTML = 'What does it mean for <span class="profession-badge">' + word + '</span>?';
    });
    select.value = prof;
    localStorage.setItem('ai-brief-profession', prof);
  }

  setProfession(saved);

  select.addEventListener('change', function() {
    setProfession(select.value);
  });
})();
</script>
<script defer src="/_vercel/insights/script.js"></script>
</body>
</html>